{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subramaniya-pillai/data_engineering/blob/main/hr_analytics_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57985e64",
      "metadata": {
        "id": "57985e64"
      },
      "source": [
        "## Task 1: Ingestion & Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dbe0e909",
      "metadata": {
        "id": "dbe0e909"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"HR Analytics\").getOrCreate()\n",
        "\n",
        "# Load CSV and JSON files\n",
        "emp_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/employees (1).csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "att_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/attendance.csv\")\n",
        "bonus_df = spark.read.option(\"multiline\", True).json(\"bonuses.json\")\n",
        "\n",
        "# Show schemas and samples\n",
        "emp_df.printSchema()\n",
        "emp_df.show()\n",
        "\n",
        "att_df.printSchema()\n",
        "att_df.show()\n",
        "\n",
        "bonus_df.printSchema()\n",
        "bonus_df.show()\n",
        "\n",
        "# Count distinct departments\n",
        "emp_df.select(\"Department\").distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlSgkcdlYaDH",
        "outputId": "d3297c5b-b0d8-4d54-bd3c-e3d13e350199"
      },
      "id": "VlSgkcdlYaDH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: double (nullable = true)\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|      1.0|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "|    3|2024-04-02|Present|\n",
            "|    4|2024-04-01| Absent|\n",
            "|    4|2024-04-02| Absent|\n",
            "|    5|2024-04-01|Present|\n",
            "|    5|2024-04-02|Present|\n",
            "+-----+----------+-------+\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ea52e7",
      "metadata": {
        "id": "99ea52e7"
      },
      "source": [
        "## Task 2: DataFrame Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09e9001c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09e9001c",
        "outputId": "714697f8-edba-4e1a-ec4a-117b5f386de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+\n",
            "|EmpID|  Name|TenureYears|\n",
            "+-----+------+-----------+\n",
            "|    1| Anita|       4.11|\n",
            "|    2|   Raj|       5.24|\n",
            "|    3|Simran|       2.92|\n",
            "|    4| Aamir|       5.56|\n",
            "|    5| Nisha|       2.43|\n",
            "+-----+------+-----------+\n",
            "\n",
            "+-----+------+-----------------+\n",
            "|EmpID|  Name|TotalCompensation|\n",
            "+-----+------+-----------------+\n",
            "|    1| Anita|            60000|\n",
            "|    2|   Raj|            87000|\n",
            "|    3|Simran|            81500|\n",
            "|    4| Aamir|            66000|\n",
            "|    5| Nisha|            54000|\n",
            "+-----+------+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|       5.24| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|       5.56| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|      1.0|       2.43| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|       5.24|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|       5.56|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|      1.0|       2.43|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import datediff, current_date, round, col\n",
        "\n",
        "# Add TenureYears\n",
        "emp_df = emp_df.withColumn(\"TenureYears\", round(datediff(current_date(), col(\"JoinDate\")) / 365, 2))\n",
        "emp_df.select(\"EmpID\", \"Name\", \"TenureYears\").show()\n",
        "\n",
        "# TotalCompensation\n",
        "emp_bonus_df = emp_df.join(bonus_df, \"EmpID\").withColumn(\"TotalCompensation\", col(\"Salary\") + col(\"Bonus\"))\n",
        "emp_bonus_df.select(\"EmpID\", \"Name\", \"TotalCompensation\").show()\n",
        "\n",
        "# More than 2 years\n",
        "emp_bonus_df.filter(col(\"TenureYears\") > 2).show()\n",
        "\n",
        "# With Manager\n",
        "emp_df.filter(col(\"ManagerID\").isNotNull()).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fdd8cf3",
      "metadata": {
        "id": "3fdd8cf3"
      },
      "source": [
        "## Task 3: Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3d7b21d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7b21d0",
        "outputId": "b003f765-bf7c-4f44-9975-de5e3787da5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "| Department|avg(Salary)|\n",
            "+-----------+-----------+\n",
            "|Engineering|    77500.0|\n",
            "|         HR|    52500.0|\n",
            "|  Marketing|    60000.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "+---------+------------+\n",
            "|ManagerID|NumEmployees|\n",
            "+---------+------------+\n",
            "|     NULL|           1|\n",
            "|      1.0|           4|\n",
            "+---------+------------+\n",
            "\n",
            "+-----+------------+\n",
            "|EmpID|AbsenceCount|\n",
            "+-----+------------+\n",
            "|    4|           2|\n",
            "|    2|           1|\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Avg salary per department\n",
        "emp_df.groupBy(\"Department\").avg(\"Salary\").show()\n",
        "\n",
        "# Employees under each manager\n",
        "emp_df.groupBy(\"ManagerID\").count().withColumnRenamed(\"count\", \"NumEmployees\").show()\n",
        "\n",
        "# Absences per employee\n",
        "att_df.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").count().withColumnRenamed(\"count\", \"AbsenceCount\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5110c9d2",
      "metadata": {
        "id": "5110c9d2"
      },
      "source": [
        "## Task 4: Joins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "efeb2bb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efeb2bb7",
        "outputId": "6826e3a3-992e-40e6-80c4-9cac6ee8535c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-------------+\n",
            "|EmpID|  Name|AttendancePct|\n",
            "+-----+------+-------------+\n",
            "|    1| Anita|        100.0|\n",
            "|    3|Simran|        100.0|\n",
            "|    5| Nisha|        100.0|\n",
            "|    4| Aamir|          0.0|\n",
            "|    2|   Raj|         50.0|\n",
            "+-----+------+-------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|       5.24| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|       5.56| 6000|2023|            66000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|      Date| Status|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|2024-04-02|Present|\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|2024-04-01|Present|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|       5.24| 7000|2023|2024-04-02|Present|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|      1.0|       5.24| 7000|2023|2024-04-01| Absent|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92| 6500|2023|2024-04-02|Present|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92| 6500|2023|2024-04-01|Present|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|       5.56| 6000|2023|2024-04-02| Absent|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|      1.0|       5.56| 6000|2023|2024-04-01| Absent|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|      1.0|       2.43| 4000|2023|2024-04-02|Present|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|      1.0|       2.43| 4000|2023|2024-04-01|Present|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import count, sum, when\n",
        "\n",
        "# Attendance %\n",
        "att_pct_df = att_df.groupBy(\"EmpID\").agg(\n",
        "    count(\"*\").alias(\"TotalDays\"),\n",
        "    sum(when(col(\"Status\") == \"Present\", 1).otherwise(0)).alias(\"PresentDays\")\n",
        ").withColumn(\"AttendancePct\", round(col(\"PresentDays\") / col(\"TotalDays\") * 100, 2))\n",
        "\n",
        "emp_att_pct_df = emp_df.join(att_pct_df, \"EmpID\")\n",
        "emp_att_pct_df.select(\"EmpID\", \"Name\", \"AttendancePct\").show()\n",
        "\n",
        "# Top 3 by compensation\n",
        "emp_bonus_df.orderBy(col(\"TotalCompensation\").desc()).limit(3).show()\n",
        "\n",
        "# Multi-level join\n",
        "multi_df = emp_df.join(bonus_df, \"EmpID\").join(att_df, \"EmpID\")\n",
        "multi_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4edbd40a",
      "metadata": {
        "id": "4edbd40a"
      },
      "source": [
        "## Task 5: String & Date Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a0917fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0917fde",
        "outputId": "ab0042a9-6296-4af6-c940-d4d15098dbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+--------+---------+\n",
            "|EmpID|  JoinDate|JoinYear|JoinMonth|\n",
            "+-----+----------+--------+---------+\n",
            "|    1|2021-05-01|    2021|        5|\n",
            "|    2|2020-03-15|    2020|        3|\n",
            "|    3|2022-07-10|    2022|        7|\n",
            "|    4|2019-11-20|    2019|       11|\n",
            "|    5|2023-01-05|    2023|        1|\n",
            "+-----+----------+--------+---------+\n",
            "\n",
            "+-----+------+----------+\n",
            "|EmpID|  Name|MaskedName|\n",
            "+-----+------+----------+\n",
            "|    1| Anita|     A****|\n",
            "|    2|   Raj|       R**|\n",
            "|    3|Simran|    S*****|\n",
            "|    4| Aamir|     A****|\n",
            "|    5| Nisha|     N****|\n",
            "+-----+------+----------+\n",
            "\n",
            "+-----+-------+\n",
            "|EmpID|EmpCode|\n",
            "+-----+-------+\n",
            "|    1| EMP001|\n",
            "|    2| EMP002|\n",
            "|    3| EMP003|\n",
            "|    4| EMP004|\n",
            "|    5| EMP005|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import year, month, regexp_replace, lpad, lit, concat\n",
        "\n",
        "# Extract year and month\n",
        "emp_df = emp_df.withColumn(\"JoinYear\", year(\"JoinDate\")).withColumn(\"JoinMonth\", month(\"JoinDate\"))\n",
        "emp_df.select(\"EmpID\", \"JoinDate\", \"JoinYear\", \"JoinMonth\").show()\n",
        "\n",
        "# Mask names\n",
        "emp_df = emp_df.withColumn(\"MaskedName\", regexp_replace(\"Name\", \"(?<=.).\", \"*\"))\n",
        "emp_df.select(\"EmpID\", \"Name\", \"MaskedName\").show()\n",
        "\n",
        "# EmpCode\n",
        "emp_df = emp_df.withColumn(\"EmpCode\", lpad(col(\"EmpID\").cast(\"string\"), 3, \"0\"))\n",
        "emp_df = emp_df.withColumn(\"EmpCode\", concat(lit(\"EMP\"), col(\"EmpCode\")))\n",
        "emp_df.select(\"EmpID\", \"EmpCode\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8ceb3fc",
      "metadata": {
        "id": "f8ceb3fc"
      },
      "source": [
        "## Task 6: Conditional & Null Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3ff65329",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ff65329",
        "outputId": "343b87f9-0399-4ba1-8e62-f7531a600ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+\n",
            "|EmpID|Bonus|Performance|\n",
            "+-----+-----+-----------+\n",
            "|    1| 5000|     Medium|\n",
            "|    2| 7000|       High|\n",
            "|    3| 6500|       High|\n",
            "|    4| 6000|     Medium|\n",
            "|    5| 4000|     Medium|\n",
            "+-----+-----+-----------+\n",
            "\n",
            "+-----+---------+\n",
            "|EmpID|ManagerID|\n",
            "+-----+---------+\n",
            "|    1|     NULL|\n",
            "|    2|      1.0|\n",
            "|    3|      1.0|\n",
            "|    4|      1.0|\n",
            "|    5|      1.0|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Performance label\n",
        "bonus_df = bonus_df.withColumn(\"Performance\",\n",
        "    when(col(\"Bonus\") > 6000, \"High\")\n",
        "    .when((col(\"Bonus\") >= 4000) & (col(\"Bonus\") <= 6000), \"Medium\")\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "bonus_df.select(\"EmpID\", \"Bonus\", \"Performance\").show()\n",
        "\n",
        "# Null handling\n",
        "emp_df = emp_df.fillna({\"ManagerID\": \"No Manager\"})\n",
        "emp_df.select(\"EmpID\", \"ManagerID\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f0efe1",
      "metadata": {
        "id": "65f0efe1"
      },
      "source": [
        "## Task 7: Spark SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "11a8e511",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11a8e511",
        "outputId": "30a412df-6e41-490c-c143-8a9fde806815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+------+\n",
            "| Department| Name|Salary|\n",
            "+-----------+-----+------+\n",
            "|         HR|Anita| 55000|\n",
            "|Engineering|  Raj| 80000|\n",
            "|  Marketing|Aamir| 60000|\n",
            "+-----------+-----+------+\n",
            "\n",
            "+-----------+--------------+\n",
            "| Department|AttendanceRate|\n",
            "+-----------+--------------+\n",
            "|Engineering|          0.75|\n",
            "|         HR|           1.0|\n",
            "|  Marketing|           0.0|\n",
            "+-----------+--------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|EmpCode|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|      1.0|       2.92|    2022|        7|    S*****| EMP003|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS hr\")\n",
        "spark.catalog.setCurrentDatabase(\"hr\")\n",
        "\n",
        "emp_df.write.mode(\"overwrite\").saveAsTable(\"employees\")\n",
        "att_df.write.mode(\"overwrite\").saveAsTable(\"attendance\")\n",
        "bonus_df.write.mode(\"overwrite\").saveAsTable(\"bonuses\")\n",
        "\n",
        "# Queries\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Department, Name, Salary FROM employees e\n",
        "    WHERE Salary = (SELECT MAX(Salary) FROM employees e2 WHERE e.Department = e2.Department)\n",
        "\"\"\").show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT e.Department, ROUND(SUM(CASE WHEN a.Status = 'Present' THEN 1 ELSE 0 END)/COUNT(*), 2) AS AttendanceRate\n",
        "    FROM employees e JOIN attendance a ON e.EmpID = a.EmpID\n",
        "    GROUP BY e.Department\n",
        "\"\"\").show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT * FROM employees\n",
        "    WHERE JoinDate > '2021-01-01' AND Salary > 70000\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120883f6",
      "metadata": {
        "id": "120883f6"
      },
      "source": [
        "## Task 8: Advanced (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d52dcd00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d52dcd00",
        "outputId": "4de683f9-7942-4199-f706-07a1df1fdaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+------------+\n",
            "|EmpID| Department|DeptCategory|\n",
            "+-----+-----------+------------+\n",
            "|    1|         HR|    Non-Tech|\n",
            "|    2|Engineering|        Tech|\n",
            "|    3|Engineering|        Tech|\n",
            "|    4|  Marketing|    Non-Tech|\n",
            "|    5|         HR|    Non-Tech|\n",
            "+-----+-----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# UDF to classify departments\n",
        "def classify_dept(dept):\n",
        "    return \"Tech\" if dept == \"Engineering\" else \"Non-Tech\"\n",
        "\n",
        "dept_udf = udf(classify_dept, StringType())\n",
        "emp_df = emp_df.withColumn(\"DeptCategory\", dept_udf(\"Department\"))\n",
        "emp_df.select(\"EmpID\", \"Department\", \"DeptCategory\").show()\n",
        "\n",
        "# Create view and save as Parquet\n",
        "emp_attendance_summary = emp_df.join(att_pct_df, \"EmpID\")\n",
        "emp_attendance_summary.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "emp_attendance_summary.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(\"output/emp_attendance_summary\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
